#### general settings
name: DemosaicFormer_InitialTraining
use_tb_logger: True
model: sr
distortion: sr
scale: 1
save_img: False
gpu_ids: [0, 1, 2, 3, 4, 5]


#### network structures
network_G:
  which_model_G: DemosaicFormer
  inp_channels: 3
  out_channels: 3
  dim: 48
  num_blocks: [4, 6, 6, 8]
  num_refinement_blocks: 4
  heads: [1, 2, 4, 8]
  ffn_expansion_factor: 2.66
  bias: False
  LayerNorm_type: BiasFree
  dual_pixel_task: False
  scale: 1

#### datasets
datasets:
  train:
    name: EvInt
    mode: LQGT
    use_augdata: true
    use_colorjitter: False

    dataroot_Noise: /root/autodl-tmp/MIPI_dataset/new/defect_noise.h5
    dataroot_GT: /root/autodl-tmp/MIPI_dataset/train_copy/new_gt_1024
    dataroot_Frame: /root/autodl-tmp/MIPI_dataset/train_copy/new_qS_1024

    use_shuffle: true
    n_workers: 4  # per GPU
    batch_size: 84
    batch_size_per_gpu: 14
    mini_batch_sizes: [14, 5, 3, 2]
    iters: [58000, 36000, 24000, 24000]
    GT_size: 192
    GT_sizes: [80, 128, 160, 192]
    use_flip: true
    use_rot: true
    color: RGB
    scale: 1
  val:
    name: EvInt_valid
    mode: LQGT
    dataroot_GT: /root/autodl-tmp/MIPI_dataset/test/gt_512

    dataroot_Frame: /root/autodl-tmp/MIPI_dataset/test/quadSamples_512
    scale: 1
  
#### path
path:
  pretrain_model_G: ~
  strict_load: true
  resume_state: ~
  root: /root/autodl-tmp/MIPI_res

#### training settings: learning rate scheme, loss
train:
  optim_type: Adam
  # weight_decay_G: !!float 1e-4
  lr_G: !!float 5e-4
  lr_scheme: CosineAnnealingRestartCyclicLR
  beta1: 0.9
  beta2: 0.99
  niter: 70000
  warmup_iter: -1  # no warm up
  periods: [58000, 84000]
  restart_weights: [1, 1]
  eta_mins: [0.0003, 0.0000001]

  pixel_criterion: l1
  pixel_weight: 1.0

  manual_seed: 10
  val_freq: !!float 1e4

#### logger
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 1e4